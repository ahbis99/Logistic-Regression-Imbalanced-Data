{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support,f1_score,recall_score,precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\ahmet\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ahmet\\anaconda3\\lib\\site-packages (from imblearn) (0.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\ahmet\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\ahmet\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\ahmet\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ahmet\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ahmet\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"age\",\"sex\",\"cp\",\"trestbps\",\"chol\",\"fbs\",\"restecg\",\"thalach\",\"exang\",\"oldpeak\",\"slope\",\"ca\",\"thal\",\"num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>145.000</td>\n",
       "      <td>233.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>150.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.300</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>130.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>187.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>130.000</td>\n",
       "      <td>204.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>172.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.400</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>236.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>178.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>354.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>163.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age   sex    cp  trestbps    chol   fbs  restecg  thalach  exang  \\\n",
       "0 63.000 1.000 1.000   145.000 233.000 1.000    2.000  150.000  0.000   \n",
       "1 37.000 1.000 3.000   130.000 250.000 0.000    0.000  187.000  0.000   \n",
       "2 41.000 0.000 2.000   130.000 204.000 0.000    2.000  172.000  0.000   \n",
       "3 56.000 1.000 2.000   120.000 236.000 0.000    0.000  178.000  0.000   \n",
       "4 57.000 0.000 4.000   120.000 354.000 0.000    0.000  163.000  1.000   \n",
       "\n",
       "   oldpeak  slope   ca thal       num  \n",
       "0    2.300  3.000  0.0  6.0  negative  \n",
       "1    3.500  3.000  0.0  3.0  negative  \n",
       "2    1.400  1.000  0.0  3.0  negative  \n",
       "3    0.800  1.000  0.0  3.0  negative  \n",
       "4    0.600  1.000  0.0  3.0  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/Ahmet/Desktop/data/cleveland-0_vs_4.dat\",\n",
    "            sep=',',skiprows=list(np.arange(18)),names=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dataset for the risk of heart attack with class imbalance:\n",
    "\n",
    "- Create a logistic regression model and measure the performance of it.\n",
    "- By experimenting with different methods and class ratios; overcome class imbalance, determine the best performing method and class ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 177 entries, 0 to 176\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       177 non-null    float64\n",
      " 1   sex       177 non-null    float64\n",
      " 2   cp        177 non-null    float64\n",
      " 3   trestbps  177 non-null    float64\n",
      " 4   chol      177 non-null    float64\n",
      " 5   fbs       177 non-null    float64\n",
      " 6   restecg   177 non-null    float64\n",
      " 7   thalach   177 non-null    float64\n",
      " 8   exang     177 non-null    float64\n",
      " 9   oldpeak   177 non-null    float64\n",
      " 10  slope     177 non-null    float64\n",
      " 11  ca        177 non-null    object \n",
      " 12  thal      177 non-null    object \n",
      " 13  num       177 non-null    object \n",
      "dtypes: float64(11), object(3)\n",
      "memory usage: 19.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0' '2.0' '1.0' '3.0' '<null>']\n",
      "['6.0' '3.0' '7.0' '<null>']\n"
     ]
    }
   ],
   "source": [
    "print(df.ca.unique())\n",
    "print(df.thal.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ca.replace('<null>',np.nan,inplace=True)\n",
    "df.thal.replace('<null>',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0' '2.0' '1.0' '3.0' nan]\n",
      "['6.0' '3.0' '7.0' nan]\n"
     ]
    }
   ],
   "source": [
    "print(df.ca.unique())\n",
    "print(df.thal.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          3\n",
       "thal        1\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 173 entries, 0 to 176\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       173 non-null    float64\n",
      " 1   sex       173 non-null    float64\n",
      " 2   cp        173 non-null    float64\n",
      " 3   trestbps  173 non-null    float64\n",
      " 4   chol      173 non-null    float64\n",
      " 5   fbs       173 non-null    float64\n",
      " 6   restecg   173 non-null    float64\n",
      " 7   thalach   173 non-null    float64\n",
      " 8   exang     173 non-null    float64\n",
      " 9   oldpeak   173 non-null    float64\n",
      " 10  slope     173 non-null    float64\n",
      " 11  ca        173 non-null    float64\n",
      " 12  thal      173 non-null    float64\n",
      " 13  num       173 non-null    object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 20.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.ca = df.ca.astype(\"float64\")\n",
    "df.thal = df.thal.astype(\"float64\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\"negative\" : 0, \"positive\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"num\",axis=1)\n",
    "y = df[\"num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X, y):\n",
    "    X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20, random_state=111, stratify = y)\n",
    "    \n",
    "    logreg_model = LogisticRegression()\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "\n",
    "    pred_train = logreg_model.predict(X_train)\n",
    "    pred_test = logreg_model.predict(X_test)\n",
    "    \n",
    "    conf_mtx_train = confusion_matrix(y_train, pred_train)\n",
    "    conf_mtx_test = confusion_matrix(y_test, pred_test)\n",
    "    \n",
    "    print(\"Accuracy : {}\\n\".format(logreg_model.score(X_test, y_test)))\n",
    "    \n",
    "    print(\"Train Dataset\")\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    \n",
    "    print(\"Test Dataset\")\n",
    "    print(classification_report(y_test, pred_test))\n",
    "    \n",
    "    print(\"Test Dataset - CM\")\n",
    "    print(conf_mtx_train)\n",
    "    \n",
    "    print(\"Test Dataset - CM\")\n",
    "    print(conf_mtx_test)\n",
    "    \n",
    "    return  None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9428571428571428\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       128\n",
      "           1       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.98       138\n",
      "   macro avg       0.99      0.85      0.91       138\n",
      "weighted avg       0.98      0.98      0.98       138\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        32\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.94        35\n",
      "   macro avg       0.97      0.67      0.73        35\n",
      "weighted avg       0.95      0.94      0.93        35\n",
      "\n",
      "Test Dataset - CM\n",
      "[[128   0]\n",
      " [  3   7]]\n",
      "Test Dataset - CM\n",
      "[[32  0]\n",
      " [ 2  1]]\n"
     ]
    }
   ],
   "source": [
    "create_model(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When our model is evaluated only with the accuracy score, it can be interpreted as if it works perfectly, but when we look at the recall score, we can see that it is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = y.value_counts()\n",
    "sns.barplot(data.index,data.values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When we look at our target variable, we can see that we are working on an unbalanced data set. To correct this situation, I will use methods such as SMOTE and ADASYN and will compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    160\n",
       "0    160\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = df[df.num == 0]\n",
    "positive = df[df.num == 1]\n",
    "\n",
    "positive_upsampled = resample(positive,\n",
    "                            replace = True,\n",
    "                            n_samples = len(negative),\n",
    "                            random_state = 111)\n",
    "\n",
    "upsampled_df = pd.concat([negative, positive_upsampled],ignore_index=True)\n",
    "upsampled_df.num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.953125\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98       128\n",
      "           1       0.96      1.00      0.98       128\n",
      "\n",
      "    accuracy                           0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.91      1.00      0.96        32\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.96      0.95      0.95        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[122   6]\n",
      " [  0 128]]\n",
      "Test Dataset - CM\n",
      "[[29  3]\n",
      " [ 0 32]]\n"
     ]
    }
   ],
   "source": [
    "X = upsampled_df.drop(\"num\", axis=1)\n",
    "y = upsampled_df['num']\n",
    "\n",
    "create_model(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When we run our model after balancing the numbers of our target variables with upsampling, we see that our model gives much better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    160\n",
       "1    128\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative = df[df.num == 0]\n",
    "positive = df[df.num == 1]\n",
    "sample_len = int(len(negative)*0.8)\n",
    "\n",
    "positive_upsampled = resample(positive,\n",
    "                            replace = True,\n",
    "                            n_samples = sample_len,\n",
    "                            random_state = 111)\n",
    "\n",
    "upsampled_df = pd.concat([negative, positive_upsampled],ignore_index=True)\n",
    "upsampled_df.num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9482758620689655\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       128\n",
      "           1       0.94      1.00      0.97       102\n",
      "\n",
      "    accuracy                           0.97       230\n",
      "   macro avg       0.97      0.97      0.97       230\n",
      "weighted avg       0.97      0.97      0.97       230\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.90      1.00      0.95        26\n",
      "\n",
      "    accuracy                           0.95        58\n",
      "   macro avg       0.95      0.95      0.95        58\n",
      "weighted avg       0.95      0.95      0.95        58\n",
      "\n",
      "Test Dataset - CM\n",
      "[[121   7]\n",
      " [  0 102]]\n",
      "Test Dataset - CM\n",
      "[[29  3]\n",
      " [ 0 26]]\n"
     ]
    }
   ],
   "source": [
    "X = upsampled_df.drop(\"num\", axis=1)\n",
    "y = upsampled_df['num']\n",
    "\n",
    "create_model(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When we upsample the positive values ​​up to 80% of the negative values, we can say that the accuracy value of our model drops a little, but it still gives nice results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling strategy is 0.3\n",
      "Accuracy : 0.9523809523809523\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       128\n",
      "           1       0.92      0.89      0.91        38\n",
      "\n",
      "    accuracy                           0.96       166\n",
      "   macro avg       0.94      0.94      0.94       166\n",
      "weighted avg       0.96      0.96      0.96       166\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        32\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.92      0.97      0.94        42\n",
      "weighted avg       0.96      0.95      0.95        42\n",
      "\n",
      "Test Dataset - CM\n",
      "[[125   3]\n",
      " [  4  34]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 0 10]]\n",
      "\n",
      "Sampling strategy is 0.4\n",
      "Accuracy : 0.9333333333333333\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       128\n",
      "           1       0.94      0.98      0.96        51\n",
      "\n",
      "    accuracy                           0.98       179\n",
      "   macro avg       0.97      0.98      0.97       179\n",
      "weighted avg       0.98      0.98      0.98       179\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        32\n",
      "           1       0.86      0.92      0.89        13\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.91      0.93      0.92        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "Test Dataset - CM\n",
      "[[125   3]\n",
      " [  1  50]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 1 12]]\n",
      "\n",
      "Sampling strategy is 0.5\n",
      "Accuracy : 0.9583333333333334\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       128\n",
      "           1       0.94      0.98      0.96        64\n",
      "\n",
      "    accuracy                           0.97       192\n",
      "   macro avg       0.97      0.98      0.97       192\n",
      "weighted avg       0.97      0.97      0.97       192\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        32\n",
      "           1       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.94      0.97      0.95        48\n",
      "weighted avg       0.96      0.96      0.96        48\n",
      "\n",
      "Test Dataset - CM\n",
      "[[124   4]\n",
      " [  1  63]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 0 16]]\n",
      "\n",
      "Sampling strategy is 0.6\n",
      "Accuracy : 0.9615384615384616\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       127\n",
      "           1       0.94      0.99      0.96        77\n",
      "\n",
      "    accuracy                           0.97       204\n",
      "   macro avg       0.97      0.97      0.97       204\n",
      "weighted avg       0.97      0.97      0.97       204\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        33\n",
      "           1       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.96        52\n",
      "   macro avg       0.95      0.97      0.96        52\n",
      "weighted avg       0.97      0.96      0.96        52\n",
      "\n",
      "Test Dataset - CM\n",
      "[[122   5]\n",
      " [  1  76]]\n",
      "Test Dataset - CM\n",
      "[[31  2]\n",
      " [ 0 19]]\n",
      "\n",
      "Sampling strategy is 0.7\n",
      "Accuracy : 0.9454545454545454\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98       128\n",
      "           1       0.94      1.00      0.97        89\n",
      "\n",
      "    accuracy                           0.97       217\n",
      "   macro avg       0.97      0.98      0.97       217\n",
      "weighted avg       0.97      0.97      0.97       217\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.88      1.00      0.94        23\n",
      "\n",
      "    accuracy                           0.95        55\n",
      "   macro avg       0.94      0.95      0.94        55\n",
      "weighted avg       0.95      0.95      0.95        55\n",
      "\n",
      "Test Dataset - CM\n",
      "[[122   6]\n",
      " [  0  89]]\n",
      "Test Dataset - CM\n",
      "[[29  3]\n",
      " [ 0 23]]\n",
      "\n",
      "Sampling strategy is 0.8\n",
      "Accuracy : 0.9482758620689655\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       128\n",
      "           1       0.95      1.00      0.98       102\n",
      "\n",
      "    accuracy                           0.98       230\n",
      "   macro avg       0.98      0.98      0.98       230\n",
      "weighted avg       0.98      0.98      0.98       230\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.90      1.00      0.95        26\n",
      "\n",
      "    accuracy                           0.95        58\n",
      "   macro avg       0.95      0.95      0.95        58\n",
      "weighted avg       0.95      0.95      0.95        58\n",
      "\n",
      "Test Dataset - CM\n",
      "[[123   5]\n",
      " [  0 102]]\n",
      "Test Dataset - CM\n",
      "[[29  3]\n",
      " [ 0 26]]\n",
      "\n",
      "Sampling strategy is 0.9\n",
      "Accuracy : 0.9672131147540983\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       128\n",
      "           1       0.96      0.99      0.97       115\n",
      "\n",
      "    accuracy                           0.98       243\n",
      "   macro avg       0.97      0.98      0.98       243\n",
      "weighted avg       0.98      0.98      0.98       243\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        32\n",
      "           1       0.94      1.00      0.97        29\n",
      "\n",
      "    accuracy                           0.97        61\n",
      "   macro avg       0.97      0.97      0.97        61\n",
      "weighted avg       0.97      0.97      0.97        61\n",
      "\n",
      "Test Dataset - CM\n",
      "[[123   5]\n",
      " [  1 114]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 0 29]]\n",
      "\n",
      "Sampling strategy is 1.0\n",
      "Accuracy : 0.953125\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       128\n",
      "           1       0.96      1.00      0.98       128\n",
      "\n",
      "    accuracy                           0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        32\n",
      "           1       0.94      0.97      0.95        32\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.95      0.95      0.95        64\n",
      "weighted avg       0.95      0.95      0.95        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[123   5]\n",
      " [  0 128]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 1 31]]\n"
     ]
    }
   ],
   "source": [
    "y = df.num\n",
    "X = df.drop('num', axis=1)\n",
    "for i in [x/10 for x in range(3,11)]:\n",
    "    sm = SMOTE(random_state=27, sampling_strategy=i)\n",
    "    X_smote, y_smote = sm.fit_resample(X, y)\n",
    "    print(f\"\\nSampling strategy is {i}\")\n",
    "    create_model(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When we look at different ratios, I would prefer 0.5 or 0.6 ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For 1 neighbors\n",
      "Accuracy : 0.984375\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       128\n",
      "           1       0.97      0.99      0.98       125\n",
      "\n",
      "    accuracy                           0.98       253\n",
      "   macro avg       0.98      0.98      0.98       253\n",
      "weighted avg       0.98      0.98      0.98       253\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       0.97      1.00      0.98        32\n",
      "\n",
      "    accuracy                           0.98        64\n",
      "   macro avg       0.98      0.98      0.98        64\n",
      "weighted avg       0.98      0.98      0.98        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[124   4]\n",
      " [  1 124]]\n",
      "Test Dataset - CM\n",
      "[[31  1]\n",
      " [ 0 32]]\n",
      "\n",
      " For 2 neighbors\n",
      "Accuracy : 0.953125\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       128\n",
      "           1       0.96      1.00      0.98       128\n",
      "\n",
      "    accuracy                           0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        32\n",
      "           1       0.94      0.97      0.95        32\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.95      0.95      0.95        64\n",
      "weighted avg       0.95      0.95      0.95        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[123   5]\n",
      " [  0 128]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 1 31]]\n",
      "\n",
      " For 3 neighbors\n",
      "Accuracy : 0.9538461538461539\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       128\n",
      "           1       0.96      1.00      0.98       129\n",
      "\n",
      "    accuracy                           0.98       257\n",
      "   macro avg       0.98      0.98      0.98       257\n",
      "weighted avg       0.98      0.98      0.98       257\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.92      1.00      0.96        33\n",
      "\n",
      "    accuracy                           0.95        65\n",
      "   macro avg       0.96      0.95      0.95        65\n",
      "weighted avg       0.96      0.95      0.95        65\n",
      "\n",
      "Test Dataset - CM\n",
      "[[123   5]\n",
      " [  0 129]]\n",
      "Test Dataset - CM\n",
      "[[29  3]\n",
      " [ 0 33]]\n",
      "\n",
      " For 4 neighbors\n",
      "Accuracy : 0.953125\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       128\n",
      "           1       0.96      1.00      0.98       126\n",
      "\n",
      "    accuracy                           0.98       254\n",
      "   macro avg       0.98      0.98      0.98       254\n",
      "weighted avg       0.98      0.98      0.98       254\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        32\n",
      "           1       0.94      0.97      0.95        32\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.95      0.95      0.95        64\n",
      "weighted avg       0.95      0.95      0.95        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[123   5]\n",
      " [  0 126]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 1 31]]\n",
      "\n",
      " For 5 neighbors\n",
      "Accuracy : 0.96875\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       128\n",
      "           1       0.96      1.00      0.98       127\n",
      "\n",
      "    accuracy                           0.98       255\n",
      "   macro avg       0.98      0.98      0.98       255\n",
      "weighted avg       0.98      0.98      0.98       255\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        32\n",
      "           1       0.94      1.00      0.97        32\n",
      "\n",
      "    accuracy                           0.97        64\n",
      "   macro avg       0.97      0.97      0.97        64\n",
      "weighted avg       0.97      0.97      0.97        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[123   5]\n",
      " [  0 127]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 0 32]]\n",
      "\n",
      " For 6 neighbors\n",
      "Accuracy : 0.953125\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98       128\n",
      "           1       0.96      1.00      0.98       128\n",
      "\n",
      "    accuracy                           0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.91      1.00      0.96        32\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.96      0.95      0.95        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[122   6]\n",
      " [  0 128]]\n",
      "Test Dataset - CM\n",
      "[[29  3]\n",
      " [ 0 32]]\n",
      "\n",
      " For 7 neighbors\n",
      "Accuracy : 0.96875\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       128\n",
      "           1       0.96      1.00      0.98       126\n",
      "\n",
      "    accuracy                           0.98       254\n",
      "   macro avg       0.98      0.98      0.98       254\n",
      "weighted avg       0.98      0.98      0.98       254\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        32\n",
      "           1       0.94      1.00      0.97        32\n",
      "\n",
      "    accuracy                           0.97        64\n",
      "   macro avg       0.97      0.97      0.97        64\n",
      "weighted avg       0.97      0.97      0.97        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[123   5]\n",
      " [  0 126]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 0 32]]\n",
      "\n",
      " For 8 neighbors\n",
      "Accuracy : 0.9538461538461539\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98       128\n",
      "           1       0.96      1.00      0.98       128\n",
      "\n",
      "    accuracy                           0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.92      1.00      0.96        33\n",
      "\n",
      "    accuracy                           0.95        65\n",
      "   macro avg       0.96      0.95      0.95        65\n",
      "weighted avg       0.96      0.95      0.95        65\n",
      "\n",
      "Test Dataset - CM\n",
      "[[122   6]\n",
      " [  0 128]]\n",
      "Test Dataset - CM\n",
      "[[29  3]\n",
      " [ 0 33]]\n",
      "\n",
      " For 9 neighbors\n",
      "Accuracy : 0.953125\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98       128\n",
      "           1       0.95      1.00      0.98       127\n",
      "\n",
      "    accuracy                           0.98       255\n",
      "   macro avg       0.98      0.98      0.98       255\n",
      "weighted avg       0.98      0.98      0.98       255\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        32\n",
      "           1       0.91      1.00      0.96        32\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.96      0.95      0.95        64\n",
      "weighted avg       0.96      0.95      0.95        64\n",
      "\n",
      "Test Dataset - CM\n",
      "[[122   6]\n",
      " [  0 127]]\n",
      "Test Dataset - CM\n",
      "[[29  3]\n",
      " [ 0 32]]\n",
      "\n",
      " For 10 neighbors\n",
      "Accuracy : 0.9692307692307692\n",
      "\n",
      "Train Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98       128\n",
      "           1       0.96      1.00      0.98       128\n",
      "\n",
      "    accuracy                           0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n",
      "Test Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        32\n",
      "           1       0.94      1.00      0.97        33\n",
      "\n",
      "    accuracy                           0.97        65\n",
      "   macro avg       0.97      0.97      0.97        65\n",
      "weighted avg       0.97      0.97      0.97        65\n",
      "\n",
      "Test Dataset - CM\n",
      "[[122   6]\n",
      " [  0 128]]\n",
      "Test Dataset - CM\n",
      "[[30  2]\n",
      " [ 0 33]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    ad = ADASYN(random_state=27,n_neighbors= i )\n",
    "    X_adasyn, y_adasyn = ad.fit_resample(X, y)\n",
    "    print(f\"\\n For {i} neighbors\")\n",
    "    create_model(X_adasyn, y_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can say that oversampling with 5 or 7 neighbor numbers gives better results for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If I need to just pick one method, I would prefer 0.5 or 0.6 ratio rate with SMOTE. It will be better because we wil have less data compared to other methods, that's important for performance and also the results are really satisfying for precision, accuracy score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
